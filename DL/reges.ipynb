{"metadata":{"colab":{"name":"NLP1_homework","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9471067,"sourceType":"datasetVersion","datasetId":5759612}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"###ML1_1: \nhttps://www.hackerrank.com/challenges/capturing-non-capturing-groups/problem?isFullScreen=true\n\n###ML1_2: \nhttps://www.hackerrank.com/challenges/branch-reset-groups/problem?isFullScreen=true\n\n###ML1_3: \nhttps://www.hackerrank.com/challenges/detect-html-links/problem?isFullScreen=true\n\n###ML1_4: Реализовать stemming, lemmatization & BoW на следующем датасете: https://cloud.mail.ru/public/Z4L3/vB8GcgTtK (Russian Toxic-abuse comments)","metadata":{"id":"dH7qx_irU4Y8"}},{"cell_type":"code","source":"#ML1_1: https://www.hackerrank.com/challenges/capturing-non-capturing-groups/problem?isFullScreen=true\nRegex_Pattern = r'(ok){3}+'\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T07:26:12.342639Z","iopub.execute_input":"2024-09-24T07:26:12.343073Z","iopub.status.idle":"2024-09-24T07:26:12.347838Z","shell.execute_reply.started":"2024-09-24T07:26:12.343035Z","shell.execute_reply":"2024-09-24T07:26:12.346642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###ML1_2: https://www.hackerrank.com/challenges/branch-reset-groups/problem?isFullScreen=true\n\nОтсутствует python  в выборе языка","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###ML1_3: https://www.hackerrank.com/challenges/detect-html-links/problem?isFullScreen=true\n\nКод для проверки:\n\n\n    ","metadata":{"id":"xJfkstKpqsXp","execution":{"iopub.status.busy":"2024-09-24T04:40:04.638119Z","iopub.execute_input":"2024-09-24T04:40:04.639054Z","iopub.status.idle":"2024-09-24T04:40:04.667668Z","shell.execute_reply.started":"2024-09-24T04:40:04.639007Z","shell.execute_reply":"2024-09-24T04:40:04.666495Z"}}},{"cell_type":"code","source":"import re\n\n    \nlink_pattern = re.compile(r'<a href=\"(?P<g>[^\"]*)\"(?:.*?)[\">]?>[\\s]?(?P<t>[^<>]*)<\\/')\n    \nn = input()\n    \n    \ndef search(st):\n    #o = re.search(link_pattern, st)\n    x = re.findall(link_pattern, st)\n        if x:\n            for i in range(len(x)):\n                print(x[i][0]+str(',') + x[i][1])\n                \n                \nfor i in range(int(n)):\n    st = input()\n    search(st)\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-09-25T14:02:52.587982Z","iopub.execute_input":"2024-09-25T14:02:52.588547Z","iopub.status.idle":"2024-09-25T14:02:53.028573Z","shell.execute_reply.started":"2024-09-25T14:02:52.588491Z","shell.execute_reply":"2024-09-25T14:02:53.027024Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/file-56/labeled.csv',encoding=\"utf-8\")\n\ncom = data.comment.str.replace('\\n','').str.lower()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T14:59:56.082250Z","iopub.execute_input":"2024-09-25T14:59:56.082697Z","iopub.status.idle":"2024-09-25T14:59:56.223322Z","shell.execute_reply.started":"2024-09-25T14:59:56.082656Z","shell.execute_reply":"2024-09-25T14:59:56.222153Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade nltk gensim bokeh umap-learn\n\npip install rsmorphy_lemmatizer --upgrade\n\npip install pymystem3 ","metadata":{"execution":{"iopub.status.busy":"2024-09-25T14:03:17.949019Z","iopub.execute_input":"2024-09-25T14:03:17.949430Z","iopub.status.idle":"2024-09-25T14:03:46.765348Z","shell.execute_reply.started":"2024-09-25T14:03:17.949388Z","shell.execute_reply":"2024-09-25T14:03:46.763118Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.3)\nRequirement already satisfied: bokeh in /opt/conda/lib/python3.10/site-packages (3.4.3)\nCollecting bokeh\n  Downloading bokeh-3.5.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: umap-learn in /opt/conda/lib/python3.10/site-packages (0.5.6)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2024.5.15)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\nRequirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.26.4)\nCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (7.0.4)\nRequirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from bokeh) (3.1.4)\nRequirement already satisfied: contourpy>=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh) (1.2.1)\nRequirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.10/site-packages (from bokeh) (21.3)\nRequirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh) (2.2.2)\nRequirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from bokeh) (9.5.0)\nRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.10/site-packages (from bokeh) (6.0.2)\nRequirement already satisfied: tornado>=6.2 in /opt/conda/lib/python3.10/site-packages (from bokeh) (6.4.1)\nRequirement already satisfied: xyzservices>=2021.09.1 in /opt/conda/lib/python3.10/site-packages (from bokeh) (2024.6.0)\nRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (1.2.2)\nRequirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (0.58.1)\nRequirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.10/site-packages (from umap-learn) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh) (2.1.5)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.2->umap-learn) (0.41.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=16.8->bokeh) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh) (2024.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\nDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bokeh-3.5.2-py3-none-any.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scipy, nltk, bokeh\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.14.0\n    Uninstalling scipy-1.14.0:\n      Successfully uninstalled scipy-1.14.0\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: bokeh\n    Found existing installation: bokeh 3.4.3\n    Uninstalling bokeh-3.4.3:\n      Successfully uninstalled bokeh-3.4.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngeoviews 1.12.0 requires bokeh<3.5.0,>=3.4.0, but you have bokeh 3.5.2 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npanel 1.4.5 requires bokeh<3.5.0,>=3.4.0, but you have bokeh 3.5.2 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bokeh-3.5.2 nltk-3.9.1 scipy-1.13.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.tokenize import WordPunctTokenizer\nfrom collections import Counter\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.snowball import RussianStemmer\nfrom nltk.downloader import download\nfrom nltk.corpus import stopwords\nfrom pymystem3 import Mystem","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:22:45.541504Z","iopub.execute_input":"2024-09-25T15:22:45.542042Z","iopub.status.idle":"2024-09-25T15:22:45.549370Z","shell.execute_reply.started":"2024-09-25T15:22:45.541975Z","shell.execute_reply":"2024-09-25T15:22:45.548074Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"download(\"stopwords\")","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:22:00.505913Z","iopub.execute_input":"2024-09-25T15:22:00.506419Z","iopub.status.idle":"2024-09-25T15:22:00.515957Z","shell.execute_reply.started":"2024-09-25T15:22:00.506376Z","shell.execute_reply":"2024-09-25T15:22:00.514206Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = WordPunctTokenizer()\n\nle = Mystem()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:17:28.137208Z","iopub.execute_input":"2024-09-25T15:17:28.137733Z","iopub.status.idle":"2024-09-25T15:17:36.478514Z","shell.execute_reply.started":"2024-09-25T15:17:28.137693Z","shell.execute_reply":"2024-09-25T15:17:36.477276Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":112,"outputs":[{"name":"stderr","text":"Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n","output_type":"stream"}]},{"cell_type":"code","source":"def vectorize(tokens):\n    vector=[]\n    for w in filtered_vocab:\n        vector.append(tokens.count(w))\n    return vector\ndef unique(sequence):\n    seen = set()\n    return [x for x in sequence if not (x in seen or seen.add(x))]\n\nstopword = stopwords.words(\"russian\")\n\nspecial_char=[\",\",\":\",\" \",\";\",\".\",\"?\",\"'\",'...','..','-']","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:22:51.317024Z","iopub.execute_input":"2024-09-25T15:22:51.318223Z","iopub.status.idle":"2024-09-25T15:22:51.327697Z","shell.execute_reply.started":"2024-09-25T15:22:51.318094Z","shell.execute_reply":"2024-09-25T15:22:51.326496Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"data_tok = [tokenizer.tokenize(line) for line in com]","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:23:10.583181Z","iopub.execute_input":"2024-09-25T15:23:10.583617Z","iopub.status.idle":"2024-09-25T15:23:10.856138Z","shell.execute_reply.started":"2024-09-25T15:23:10.583577Z","shell.execute_reply":"2024-09-25T15:23:10.854753Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"#Stemm\nvocab = unique(rs.stem(word) for line in data_tok for word in line) \n\nfiltered_vocab = [word for word in vocab if word not in special_char and word not in stopword]\n\nvector = [vectorize(line) for line in data_tok[:500]]\n\nlen(vocab), len(filtered_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:23:28.255681Z","iopub.execute_input":"2024-09-25T15:23:28.256169Z","iopub.status.idle":"2024-09-25T15:24:11.792467Z","shell.execute_reply.started":"2024-09-25T15:23:28.256112Z","shell.execute_reply":"2024-09-25T15:24:11.790818Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"(33642, 33554)"},"metadata":{}}]},{"cell_type":"code","source":"#Lemm\nvocab = unique(le.lemmatize(word)[0] for line in data_tok for word in line) \n\nfiltered_vocab = [word for word in vocab if word not in special_char and word not in stopword]\n\nvector = [vectorize(line) for line in data_tok[:500]]\n\nlen(vocab), len(filtered_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:32:50.511978Z","iopub.execute_input":"2024-09-25T15:32:50.512446Z","iopub.status.idle":"2024-09-25T15:34:12.765300Z","shell.execute_reply.started":"2024-09-25T15:32:50.512397Z","shell.execute_reply":"2024-09-25T15:34:12.764070Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"(33909, 33789)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}