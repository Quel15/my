{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81bae5b8-b758-4b09-8dbb-a53ac645fd11",
   "metadata": {},
   "source": [
    "# Домашнее задание 3.\n",
    "## Классификатор на сезонные ряды для построения автоматического пайплайна прогнозирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511fdb52-d344-4f28-a23a-21a96c9920bb",
   "metadata": {},
   "source": [
    "В рамках курса мы разбирали множество подходов к прогнозированию временных рядов, однако одновременно мы работали со счетным количеством рядов,\n",
    "для каждого из которых была возможность проанализировать его \"вручную\" и подобрать наилучшую модель. Но что, если мы столкнулись с задачей прогнозирования\n",
    "сразу сотен рядов? В таком случае мы уже не можем строить модель на каждый ряд вручную и нам придется либо строить одну модель сразу на все ряды и надеяться, что качество будет удовлетворительным, либо придумывать некий automl подход. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5167cb-ec94-4034-a5a6-0f402c8f315d",
   "metadata": {},
   "source": [
    "Если позволяют время и ресурсы, мы можем делать автомл \"влоб\" - перебирать множество моделей с их гиперпараметрами, и выбирать модель с наилучшим качеством на отложенной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76276ac1-e1a4-4b67-b212-4a1667131ef6",
   "metadata": {},
   "source": [
    "Другим вариантом automl подхода может служить тот, в котором мы разбиваем временные ряды на типы и для каждого типа строим модель прогнозирования, наиболее хорошо такой тип описывающую. Для того, чтобы автоматически определять тип ряда, мы строим классификатор, способный этот тип определять."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e3cca-a74e-4e5b-8402-bc0cfd744d9e",
   "metadata": {},
   "source": [
    "Одним из самых очевидных разбиений рядов на типы может быть разбиение на сезонные и не сезонные ряды. Предположение о наличии сезонности позволит использовать алгоритмы, лучше заточенные под поиск сезонных зависимостей, кроме того, это позволит сэкономить вычислительные ресурсы, так как несезонные ряды зачастую можно хорошо прогнозировать более легковесными методами. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ee77c-ae3f-46a9-9963-ebba463514d8",
   "metadata": {},
   "source": [
    "В текущем задании вам как раз и предлагается спроектировать такой бинарный классификатор, который мог бы отделять сезонные ряды от несезонных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb61f8e-d111-4473-bb79-054516aa2174",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f18e7b-b36d-4d3c-8eb3-d1b9df6b577a",
   "metadata": {},
   "source": [
    "Ниже приведен класс для обучения произвольного классификатора на датасете одномерных временных рядов, т.е. на наборе обьектов вида\n",
    "(timeseries, label). Данный класс определяет метод для получения произвольного признакового описания ряда `get_feature_vector`, использует его для получения датасета, после чего обучает на датасете бинарный классификатор удовлетворяющий sklearn estimator API.\n",
    "\n",
    "**Вам необходимо:**\n",
    "1. Определить метод `get_feature_vector`, который позволил бы выделить из временного ряда характерные признаки, указывающие на сезонность.\n",
    "2. Разбить датасет в соотношении 60/40 (train, test). Проследите за сбалансированностью классов в выборках.\n",
    "3. Обучить модель на трейне.\n",
    "4. Сделайте прогноз на тесте и получите метрики `f1`, `auc-roc`.\n",
    "5. Итоговые баллы за задание будут зависеть от значения метрик.  \n",
    "   `50 < f1,roc < 60` 4 балла  \n",
    "   `60 < f1,roc < 70` 6 баллов  \n",
    "   `70 < f1,roc < 85` 8 баллов  \n",
    "   `85 < f1,roc < 98` 9 баллов  \n",
    "   `98 < f1,roc` 10 баллов  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "id": "3aee02ab-5504-4de9-9ce0-65c051f4cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "class SeasonalClassifier:\n",
    "    def __init__(self, classifier=LogisticRegression, **kwargs):\n",
    "        self.classifier = classifier(**kwargs)\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, ts_dataset: Iterable[Tuple[pd.Series, int]], **kwargs):\n",
    "        X, y = [], []\n",
    "        for ts, label in ts_dataset:\n",
    "            feature_vector = self.get_feature_vector(ts)\n",
    "            X.append(feature_vector)\n",
    "            y.append(label)\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.classifier.fit(X, y, **kwargs)\n",
    "        self.fitted = True\n",
    "\n",
    "    def predict(self, ts: pd.Series):\n",
    "        self._check_fitted()\n",
    "        feature_vector = self.get_feature_vector(ts)\n",
    "        label = self.classifier.predict(np.array([feature_vector]))\n",
    "        return label\n",
    "\n",
    "    def predict_proba(self, ts: pd.Series):\n",
    "        self._check_fitted()\n",
    "        feature_vector = self.get_feature_vector(ts)\n",
    "        proba = self.classifier.predict_proba(np.array([feature_vector]))\n",
    "        return proba\n",
    "\n",
    " \n",
    "    def get_feature_vector(self, ts: pd.Series):\n",
    "        feature_vector = []\n",
    "        \n",
    "        \n",
    "        #ts = ts.values\n",
    "        det = detr.fit_transform(ts) #Убираю тренд тз ряда\n",
    "        \n",
    "        fourie = np.abs(np.fft.rfft(det))\n",
    "        \n",
    "                \n",
    "        ts_std = ts.std()\n",
    "        \n",
    "        if ts_std > 0:\n",
    "            ts_acf = acf(det, nlags=len(det))[1:]\n",
    "            max_idx = np.argmax(acf)\n",
    "        else:\n",
    "            ts_acf = np.zeros_like(det)\n",
    "        max_acf, min_acf = ts_acf.max(),ts_acf.min() \n",
    "        max_idx = len(ts)\n",
    "        \n",
    " \n",
    "\n",
    "        #acf \n",
    "        feature_vector.append(firstmin_ac(ts_acf))\n",
    "        feature_vector.append(ac_first_zero(ts_acf))\n",
    "        feature_vector.append(max_acf)\n",
    "        feature_vector.append(min_acf)\n",
    "        feature_vector.append(max_idx)\n",
    "        feature_vector.append(first_pos_acf(ts_acf))\n",
    "        \n",
    "        #four\n",
    "        feature_vector.append(fourie.max())\n",
    "        \n",
    "        \n",
    "        #ststist\n",
    "        \n",
    "        \n",
    "        detr_min = det.min()\n",
    "        feature_vector.append(detr_min)\n",
    "        feature_vector.append(det.max())\n",
    "        feature_vector.append(det.mean())\n",
    "        feature_vector.append(det.std())\n",
    "        feature_vector.append(np.median(det))\n",
    "        \n",
    "        min_count = len(det) - len(det[det == detr_min])\n",
    "        feature_vector.append(min_count)\n",
    "        \n",
    "        #sktime\n",
    "        feature_vector.append(mean3_stderr(ts))\n",
    "        return feature_vector\n",
    "\n",
    "    def _check_fitted(self):\n",
    "        if not self.fitted:\n",
    "            raise ValueError('This instance is not fitted yet. Call fit method first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ede4bb-6b74-463b-9d93-03664bc05f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# код для считывания датасета\n",
    "# !ВАЖНО! Не забудьте распаковать датасет перед запуском ячейки\n",
    "\n",
    "with open('dataset_clf/dataset_clf/labels.csv', 'r') as f:\n",
    "    labels = (line.replace('\\n', '').split(',') for line in f)\n",
    "    labels = dict(labels)\n",
    "    labels = {k: int(v) for k, v in labels.items()}\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for filename in Path('dataset_clf/dataset_clf/').glob('[!labels]*'):\n",
    "    ts = pd.read_json(filename, typ='series')\n",
    "    dataset.append((ts, labels[filename.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "c45c82ad-373c-4fc4-a163-e34fe0cedbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "detr = Detrender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "6b474b26-4ffd-4b0d-8e18-7b3c6f1e1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acf_first_zero(acf):\n",
    "    \"\"\"Первое значение acf меньше 0\"\"\"\n",
    "    for i in range(1, len(acf)):\n",
    "        if acf[i] <= 0:\n",
    "            return i\n",
    "\n",
    "    return len(acf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "id": "2068fbd7-3c56-4a2a-bf8e-f959120c8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean3_stderr(ts):\n",
    "    if len(ts) - 5 < 5:\n",
    "        return 0\n",
    "    res = _local_simple_mean(ts, 5)\n",
    "    return np.std(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "id": "933ed2f6-98ac-44ff-9921-8093552713b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_pos_acf(acf_):\n",
    "    nsum = 0\n",
    "    for i in acf_:\n",
    "        if c > 0:\n",
    "            nsum+=1\n",
    "    return nsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "9dc96440-a127-4d8b-affc-76eeb281f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_simple_mean(ts: np.ndarray, window):\n",
    "    res = np.zeros(len(ts) - window)\n",
    "    for i in range(len(res)):\n",
    "        nsum = 0\n",
    "        for n in range(window):\n",
    "            nsum += ts[i + n]\n",
    "            print(ts[i + n], nsum)\n",
    "        res[i] = ts[i + window] - nsum / window\n",
    "        print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "032507f3-dc9a-4f28-bb2e-3a57b4f30de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstmin_ac(acf_):\n",
    "    \"\"\"Первый минимум acf\"\"\"\n",
    "    for i in range(1, len(acf_) - 1):\n",
    "        if acf_[i] < acf_[i - 1] and acf_[i] < acf_[i + 1]:\n",
    "            return i\n",
    "    return len(acf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "17aa637c-f2b6-4e83-842e-520abd28f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def hyperparameters_search(model, param_grid):\n",
    "    \"\"\"Подбор гпиерпараметров моделей\"\"\"\n",
    "    statistics_f1 = {}\n",
    "    statistics_f1['params'] = []\n",
    "    statistics_f1['f1'] = []\n",
    "\n",
    "    for param_tuple in product(*param_grid.values()):\n",
    "        params = dict(zip(param_grid.keys(),param_tuple))\n",
    "\n",
    "\n",
    "        \n",
    "        cl = SeasonalClassifier(classifier=model, **params)\n",
    "\n",
    "        cl.fit(train)\n",
    "        predict = []\n",
    "        lab = np.array([data[1] for data in test])\n",
    "        for i in test:\n",
    "            predict.append(cl.predict(i[0]))\n",
    "        pred = np.array(predict).reshape(1,-1)[0]\n",
    "        \n",
    "        f1, roc = f1_score(lab,pred), roc_auc_score(lab,pred)\n",
    "        print(f1, roc)\n",
    "        statistics_f1['params'].append(params)\n",
    "        statistics_f1['f1'].append(f1)\n",
    "\n",
    "        \n",
    "    best = statistics_f1['params'][np.argmax(statistics_f1['f1'])]\n",
    " \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "id": "51cf86ca-d783-4857-8db4-188f0c6dda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[10,20,50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "6b5bf722-d621-46a6-8e2c-843817d7ae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9279279279279279 0.9443575110456554\n",
      "0.8778409090909091 0.9163751840942562\n",
      "0.8607594936708861 0.9045471281296024\n"
     ]
    }
   ],
   "source": [
    "b = hyperparameters_search(model = AdaBoostClassifier, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "id": "c6438bc4-7288-4d10-bb36-4eda91494a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(dataset)*.6)//2\n",
    "\n",
    "seas = [(data[0],data[1]) for data in dataset if data[1] ==1]\n",
    "not_seas = [(data[0],data[1]) for data in dataset if data[1] ==0]\n",
    "\n",
    "train = seas[:split_idx]+ not_seas[55:split_idx]\n",
    "test = seas[split_idx:]+ not_seas[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "id": "76d35b95-9b9e-4bed-b5a6-99aed9710cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9279279279279279, 0.9443575110456554)"
      ]
     },
     "execution_count": 1173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = SeasonalClassifier(classifier=AdaBoostClassifier, n_estimators=10)\n",
    "\n",
    "cl.fit(train)\n",
    "predict = []\n",
    "lab = np.array([data[1] for data in test])\n",
    "for i in test:\n",
    "    predict.append(cl.predict(i[0]))\n",
    "\n",
    "\n",
    "pred = np.array(predict).reshape(1,-1)[0]\n",
    "f1_score(lab,pred), roc_auc_score(lab,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "id": "d3e49c06-b724-425e-933b-bd5e9c388379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "id": "6568d994-94bd-4ac9-bdc2-01ff5a3490b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9605839416058394,\n",
       "  'recall': 0.9690721649484536,\n",
       "  'f1-score': 0.9648093841642228,\n",
       "  'support': 679},\n",
       " '1': {'precision': 0.9363636363636364,\n",
       "  'recall': 0.9196428571428571,\n",
       "  'f1-score': 0.9279279279279279,\n",
       "  'support': 336},\n",
       " 'accuracy': 0.9527093596059113,\n",
       " 'macro avg': {'precision': 0.9484737889847379,\n",
       "  'recall': 0.9443575110456554,\n",
       "  'f1-score': 0.9463686560460753,\n",
       "  'support': 1015},\n",
       " 'weighted avg': {'precision': 0.9525661853877309,\n",
       "  'recall': 0.9527093596059113,\n",
       "  'f1-score': 0.9526003503756562,\n",
       "  'support': 1015}}"
      ]
     },
     "execution_count": 1174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(lab,pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30600fa3-1785-4001-a57f-432c10f4822d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
